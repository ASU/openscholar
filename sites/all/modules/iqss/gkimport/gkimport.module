<?php

include_once('gkimport.drush.inc');

define(GKIMPORT_FS_PATH,  '/nfs/www/edu-harvard-iq-scholar-dev3'); //file system path to drupal root (NO TRAILING SLASH)
define(GKIMPORT_DOWNLOAD, FALSE);  // TRUE tells module to download files with wget, otherwise assumes files stored locally

/**
 * Begins import process
  */
function gkimport_import($drush_run = 0){
  variable_set('gkimport_drush_run', $drush_run);
  $mode = (GKIMPORT_DOWNLOAD) ? 'TRUE' : 'FALSE';
  drush_print("Begining import... (download mode is set to $mode)");
  
  gkimport_clean(); // NOTE: This should be removed when run on production
  gkimport_create_site();
  gkimport_parse_files();
  gkimport_parse_abstracts();
  gkimport_upload_pdfs();
  gkimport_update_aliases();
  gkimport_create_profiles();

  $message = 'Import completed';
  $complete = ($drush_run  === 1) ?  drush_print(t("$message")) : drupal_set_message(t("$message"));
}

/**
 * Function to create gking user account and web site
 * @return 
 *  If vsite created , then  vsite object, otherwise false
 */
function gkimport_create_site(){ 
  vsite_include('vsiteapi');
  install_include(array('user'));

  //gary's site base info
  $settings = array(
  'name' => 'gking',
  'mail' => 'jweiner@iq.harvard.edu',  // 'king@harvard.edu'
  'pass' => 'test',
  'roles' => array(variable_get('scholar_manager_role', 'scholar admin')),
  'domain' => 'gking',
  'preset' => variable_get('scholar_default_preset', 'scholar'),
  );

  //if user already exists then skip
  if(db_result(db_query("SELECT name from {users} WHERE name = '%s'", $settings['name']))){
    drupal_set_message(t("A user account already exists for %name", array('%name' => $settings['name'])));
    return FALSE;
  }

  //otherwise create user account/roles/site
  else{
    $rid = array_search(variable_get('scholar_manager_role', 'scholar admin'), user_roles());
    $user = install_add_user($settings['name'], $settings['pass'], $settings['mail'], $settings['roles'], $status = 1);
    if ($user) {
     $mesage = variable_get('gkimport_drush_run', 0) === 1 ?  drush_print(t('Created user account: !username', array('!username' => $settings['name']))) : ''; 
    }
    $vsite = vsite_vsite_create($settings['name'], $settings['domain'], $settings['preset']);
    if ($vsite){
      $mesage = variable_get('gkimport_drush_run', 0) === 1 ? drush_print(t('Created web site: !domain', array('!domain' => $settings['domain']))) : '';     
      return $vsite;
    }
  }
}

/**
 * Looks for files and calls approproiate handler functions
 * to import data
 */
function gkimport_parse_files(){
  //NOTE: Please do not change the order of these files as it can cause problems
  $files =array('pubs_taxonomy.csv', 'gkpubs.bib');  //files to parse
  $path = dirname(__FILE__) . '/files/';

  foreach($files as $file){
    $filepath = $path . $file;

    switch($file){

      case 'pubs_taxonomy.csv':
        gkimport_pubs_taxonomy($filepath);
        break;

      case 'gkpubs.bib':
        gkimport_import_pubs($file);
        break;
    }
  }
}

/**
 * Imports abstract text into publication nodes
 */
function gkimport_parse_abstracts(){
  $drush_run = variable_get('gkimport_drush_run', 0);
  $error_nodes = array();
  $nids = variable_get('gkimport_pub_nodes', array()); //array of node id's of publications created from biblio import
  //check to see that variable contains data
  if (empty($nids)) {
    $message =  'An error has occurred: gkimport_publications variable is an empty array';
    return  ($drush_run  === 1) ?  drush_print(t("$message")) : drupal_set_message(t("$message"));
  }

  $start = ($drush_run  === 1)  ?  drush_print(t("Starting to parse abstract files...")) : '';
  $path = drupal_get_path('module', 'gkimport');
  $fullpath_tmp =  GKIMPORT_FS_PATH . '/' . $path . '/tmp';  $line = (__LINE__); //mark this line for error reporting

  //make sure path exists before proceeding
  if (!is_dir($fullpath_tmp)){
    $message =  'An error has occurred: full path specified (!directory) is not a directory on line !line';
    return  ($drush_run  === 1) ?  drush_print(t("$message", array('!directory' => $fullpath_tmp, '!line' => $line))) :
    drupal_set_message(t("$message", array('!directory' => $fullpath_tmp, '!line' => $line)));
  }

  foreach($nids as $nid){
    $node = node_load(array('nid' => $nid));
    $matches = gkimport_parse_abstract_url($node);
    
    if (count($matches) && strlen($matches[2])){
      $url = trim($matches[2]);
      $filename = substr($url ,-1) == '/'  ? 'index.html' : basename($url);
      $file = $fullpath_tmp . '/' . $filename;

      // download the file
      if(GKIMPORT_DOWNLOAD){
        $cmd =  "cd $fullpath_tmp && wget -t 2 -nv -nc $url";  //no clobber specified so files with same name overwrite
        shell_exec($cmd);
      }
      if (is_file($file)){
        // clean up the text
        $text = gkimport_clean_abstract_contents(file_get_contents($file));

        //update the biblio table. TODO: node_save() may be too expensive here???
        $sql = db_query("UPDATE {biblio} SET biblio_abst_e = '%s' WHERE nid = %d", $text, (int)$node->nid);
      }
    }
    //list nodes without http accessable abstract files (field could be NULL or contain hdl:// referencing)
    else{
      $_SESSION['gkimport_na_pub_nodes'][] = $nid; //this is an array which captures all of the publication node id's without abstracts
      if ( $drush_run  === 1)  {
        //drush_print(t("Error parsing node {$node -> nid} abstract url."));
      }else{
        dpm(t("Error parsing node !nid abstract url. Either the url is missing or is using alternative referencing.", array('!nid' => $node -> nid)));
      }
    }
  }
  //cleanup any remaining files
   if(GKIMPORT_DOWNLOAD){
     $cmd =  "rm $fullpath_tmp" . '/*';
     shell_exec($cmd);
   }
  variable_set('gkimport_na_pub_nodes', $_SESSION['gkimport_na_pub_nodes']);
  if ( $drush_run  === 1) {
    drush_print(t("!num publications have been imported without abstract text.", array('!num' => count($_SESSION['gkimport_na_pub_nodes']))));
    drush_print(t("The node ID's for these publications have been saved in system variable: gkimport_na_pub_nodes"));
  }
}

/**
 * Parse abstract URL
 * 
 * @return 
 *  an array per the regex matches
 */
function gkimport_parse_abstract_url($node){
  //make curly brackets uniform around urls
     $notes = substr($node -> biblio_notes,  0, 1) !== '{' ? '{' . $node -> biblio_notes : $node -> biblio_notes;
     $notes = substr($notes, -1,1 ) !== '}' ? $notes . '}' : $notes;
      
     //check to see if http url exists in biblio notes field
     preg_match('/({)(http:\/\/.*?)(})/', $notes, $matches);
     return $matches;
 }

 /**
 * Remove uneeded html tags and javascript
 * from abstract text(s)
 */
function  gkimport_clean_abstract_contents($contents){
  $remove_js = array('displayBodyClasses()', 'displayHeader()', 'displayFooter()');  
  $text = strip_tags($contents);  
  foreach($remove_js as $js){
    $text = str_ireplace($js, '', $text);    
  }
   return  trim($text);
 }

/**
 * Import taxonomy terms and save csv information to a system variable
 */
function gkimport_pubs_taxonomy($filepath){
  install_include(array('taxonomy'));
  if (( $handle = fopen($path . $filepath, "r")) !== FALSE) {
    $all_terms = array();
    $account = user_load(array('name' => 'gking'));
    $space = vsite_get_vsite_by_owner($account -> uid);
    
    //create vocabulary(s)
     $vocab_name =  'Research Interests';
    $properties = array(
    'tags' => 1,
    'description' => 'Gary King Research Interests',
    'help' => 'Gary King Research Interests',
    );
    $content_types = array(
    'biblio' => 'biblio',
    );
      
    $vid = install_taxonomy_add_vocabulary($vocab_name, $content_types, $properties);
    if ($vid){
    og_vocab_write_record($space[0] -> group -> nid, $vid);
    variable_set('gkimport_ri_vocab_id', $vid); //keep track of vid because other vocabs may have same name
     $message =  (variable_get('gkimport_drush_run', 0) === 1) ? 
     drush_print(t("Created vocabulary: !vocab_name", array('!vocab_name' => $vocab_name))) : '';     
    }
    $term_match_data = array();
    
    //parse csv data
    while (($data = fgetcsv($handle, 1024, ",")) !== FALSE) {      
      //if title exists already in the array, and another term is to be added
      if (key_exists($data[3], $term_match_data)){
                $val = $term_match_data[$data[3]];
                 $term_match_data[$data[3]] = $val . ', ' . trim($data[0]);
                 continue;
      }
      else{
      $term_match_data[$data[3]] = $data[0];  //set title to term mapping data in an array
      }
      $all_data[] = $data;
      $all_terms[] = trim($data[0]);      
    }
    
    //refine list of terms - remove duplicates
    $terms = array_unique($all_terms);
    //set title to term mapping data in system variable to be used later
    variable_set('gkimport_taxonomy_data', $term_match_data);
     
    //save all publicaiton data from the csv to a system variable to be used later
    variable_set('gkimport_all_pub_data', $all_data);

 //add all terms to vocab - TODO not sure if we need to pre-create all terms before nodes created ???
 foreach($terms as $term){
      if (trim(strlen($term))){
        install_taxonomy_add_term($vid, trim($term));
        if  (variable_get('gkimport_drush_run', 0) === 1)  drush_print(t("Added term: !term", array('!term'=> $term)));
      }
    }
  }
}

/**
 * Matches title and returns the corresponding term(s)
 * @param  
 *  Title of node
 * @return 
 *  Return the term for matching title otherwise return NULL
 */
function gkimport_match_terms($title){
  //term match data
  $tmd = variable_get('gkimport_taxonomy_data', array());
   return isset($tmd[$title]) ? $tmd[$title] : NULL;
}

/**
 * Imports publication nodes from a Bibtex file
 */
function gkimport_import_pubs($filename, $owner = 'gking' ){
  module_load_include('inc', 'biblio', 'biblio.import.export');
  $account = user_load(array('name' => $owner));
  
  $file =new stdClass();
  $file -> filepath = dirname(__FILE__) . '/files/' . $filename;
  $file->filename = $filename;

  //settings params for biblio import
  $p = array(
  'import_file' => $file,
  'filetype' => 'bib',
  'userid' => $account -> uid,
  'terms' => NULL,
  'batch_proc' => (variable_get('gkimport_drush_run', 0) === 1)  ? FALSE : TRUE, //set to TRUE to batch process import, otherwise set to false
  'session_id' => microtime(),
  'dummy' => array(),
  'context' => array(
  'message' => t('Parsing file')
    ),
  );
  //batch process the bibtex import
  if ( $p['batch_proc'] === TRUE){
    $session_id = microtime();
    $batch_op = array(
    'title' => t('Importing '. $p['import_file'] ->filename),
    'operations' => array(
    array('biblio_import', array($p['import_file'], $p['filetype'], $p['userid'], $p['terms'], $p['batch_proc'], $p['session_id'])),
    array('biblio_import_batch_operations', array($p['session_id'], $p['userid'], $p['terms'])),
    ),
    'progressive' => TRUE,
    'finished' => 'biblio_import_batch_finished',
    'init_message' => t('Parsing file...'),
    'progress_message' => t('Importing Gary\'s Publications...'),
    'file' => './'. drupal_get_path('module', 'biblio') .'/biblio.import.export.inc'
    );
    batch_set($batch_op);
    $base = variable_get('biblio_base', 'biblio');
    batch_process("$base/import");    
  }
  //non-batch process the bibtex import
  else{ 
    //parse bibtex file and create publication nodes
    $content = biblio_import($p['import_file'], $p['filetype'], $p['userid'], $p['terms'], $p['batch_proc'], $p['session_id'], $p['context']);
    if ($content){
     variable_set('gkimport_pub_nodes', $content);   //an enumerative array of node id's of publications created during the import 
    $message = variable_get('gkimport_drush_run', 0) === 1 ?  drush_print(t('Created !num publications total', array('!num' => count($content)))) : '';
    }  
  }
}


function gkimport_upload_pdfs(){
  $nids = variable_get('gkimport_pub_nodes', array()); //array of node id's of publications created from biblio import
  //check to see that variable contains data
  if (!empty($nids)) {
    foreach ($nids as $nid){
      $node = node_load($nid);
      foreach(variable_get('gkimport_all_pub_data', array()) as $data ){
        if (trim($node -> title) == trim($data[3])){ //$data[3] is the node title
          $file = gkimport_get_pdf($node, $data[2]); //$data[2] is url to pdf
          continue;
        }
      }
    }
  }
}

function gkimport_get_pdf($node, $url){
  $path = drupal_get_path('module', 'gkimport');
  $fullpath_tmp =  GKIMPORT_FS_PATH . '/' . $path . '/tmp';
  $files_dir = GKIMPORT_FS_PATH . '/' . variable_get('file_directory_path', conf_path() .'/files') . '/gking/files';
  $source = $files_dir  . '/' . basename($url);
  

  // download the file
  if(GKIMPORT_DOWNLOAD){
    $cmd =  "cd  $files_dir && wget -t 2 -nv -nc $url";  //no clobber specified so files with same name overwrite
    shell_exec($cmd);
  }

  if (is_file($source)){
    $file = new stdClass();
    $file -> uid = $node -> uid;
    $file -> nid = $node -> nid;
    $file -> vid = $node -> vid;
    $file -> description = basename($source);
    $file ->list = 1;
    $file -> weight = 0;
    $file -> filename = basename($source);
     $file -> filepath = variable_get('file_directory_path', conf_path() .'/files') . '/gking/files/' . basename($source);
    $file -> filemime = file_get_mimetype($source);
    $file -> filesize = filesize($source);
    $file -> status =1;
    $file -> timestamp = filemtime($source);

    //write data to files table
    drupal_write_record('files', $file);
    $fid = db_last_insert_id('files', 'fid');
    //write data to upload table
    drupal_write_record('upload', $file);
    db_query("DELETE FROM  {url_alias} WHERE dst = '%s' ", 'files/' . basename($source));
    db_query("INSERT INTO {url_alias} (src, dst) VALUES ('%s', '%s')", "filefield_paths/alias/$fid", 'files/' . basename($source));

    drush_print("Added custom path for file: " . basename($source));
    
    //return file object
    return $file;
  }
}

function gkimport_update_aliases(){
  $nids = variable_get('gkimport_pub_nodes', array()); //array of node id's of publications created from biblio import
  //check to see that variable contains data
  if (!empty($nids)) {
    foreach ($nids as $nid){
      $node = node_load($nid);
      $matches = gkimport_parse_abstract_url($node);      
      //save custom path
      if (count($matches) && strlen($matches[2])){
        $path = strstr($matches[2], 'files');        
        if (strlen($path)){
          $src = db_result(db_query("SELECT src FROM {url_alias} WHERE src = '%s'", "node/{$node -> nid}"));
          db_query("DELETE FROM {url_alias} WHERE dst = '%s' ", $path);
          db_query("DELETE FROM {url_alias} WHERE src = '%s' ", $src);
          db_query("INSERT INTO {url_alias} (src, dst) VALUES ('%s', '%s')", "node/{$node -> nid}", $path);
          
          drush_print("Added custom path $path for node {$node -> nid}");          
        }
      }
    }
  }
}

function gkimport_parse_profiles(){
  $file = dirname(__FILE__) . '/files/group.html';
  $profile = file_get_contents($file);

  $group = 'Current Research Associates'; //intialize group as this string for first set of profiles

  //check to see if http url exists in biblio notes field
  preg_match_all('/<li>(.*?)<\/li>/s',$profile, $matches); 

  foreach($matches[1] as $info){
    preg_match('/href=\"(.*?)"(.*?)>(.*?)<\/a>(.*)/s',$info, $data); //$data[1]  = website  //$data[3]  = name   //$data[4]  = description
    $website = valid_url(trim($data[1]), TRUE) ? trim($data[1]) : '';
        
    $name = strip_tags(trim($data[3]));
    if (!strlen($name)) continue;  //if no name then continue to next loop

    //take the first occurrance of name in group to mark group sections
    switch($name){
      case 'Christopher Adolph':
        $group = 'Alumni: Students';
        break;

      case 'Greg Adams':
        $group = 'Alumni: Post-Docs';
        break;

      case 'Lada Adamic':
        $group = 'Collaborators';

      default:
        break; // do nothing
    }

    //clean up description text and remove comma if at beginning
    $description =  strip_tags(trim($data[4]));
    $profiles[] = array(
    'name' => $name,
    'description' => ($description[0] == ',') ? substr($description, 1): $description,
    'group' => $group,
    'website' => $website,
    );
  }
  return $profiles;
}

/**
 * Get profile data and save as profile nodes
 */
function gkimport_create_profiles(){
  module_load_include('inc', 'node', 'node.pages');
  install_include(array('taxonomy'));
  $account = user_load(array('name' => 'gking'));
  $vsites = vsite_get_vsite_by_owner($account -> uid);
  $sid = $vsites[0] -> group -> nid;

  //create new vocab for Research Group
  $vid =  _gkimport_create_rg_vocab($vsites[0]);
  
  //create terms
  _gkimport_create_rg_terms($vid);
  
  $profiles = array_reverse(gkimport_parse_profiles());

  foreach($profiles as $profile){
  //get term id for profile
  $tid = install_taxonomy_get_tid(trim($profile['group']), $vid);
  
    //split firstname and lastname
    $name = _gkimport_split_name($profile['name']);
    $check = db_result(db_query("SELECT CONCAT_WS(' ' , nid, field_person_firstname_value, field_person_lastname_value) as 
   check_name FROM {content_type_person} WHERE field_person_firstname_value = '%s' AND field_person_lastname_value = '%s'",
   $name['firstname'] , $name['lastname']));
    
   //THIS SECTION RUNS WHEN DUPLICATE NAME IS FOUND
   if(strlen( $check )) {    
   $check_name = explode(' ', $check);
   drush_print("Duplicate name encountered:  " . trim($check_name[1]) . ' '  . trim($check_name[2] . ' ' . $profile['group']));   

   //add taxonomy term only
   $nid = trim($check_name[0]);  
   db_query('DELETE FROM {term_node} WHERE nid = %d AND tid = %d', $nid, $tid);
   db_query("INSERT INTO {term_node} (nid, vid, tid) VALUES (%d, %d, %d)", $nid, $nid, $tid); 
   
   //TODO: need transfer body text to field_person_institution if $profile['group'] == 'Current Research Associates'
   if($profile['group'] == 'Current Research Associates'){
     $inst = db_result(db_query("SELECT body from {node_revisions} WHERE nid = %d", $nid));
     if(strlen($inst)){       
       db_query("UPDATE {content_type_person} SET field_person_institution_value = '%s' WHERE nid = %d ", $inst, $nid);
       }
       $description = _gkimport_remove_line_breaks($profile['description']);  
       db_query("UPDATE {node_revisions} SET body = '%s',  teaser = '%s',  uid = %d WHERE nid = %d", $description, $description, (int)$account -> uid, (int)$nid);
       //drush_print("Updating description: for $nid - $description");
    }
   continue;   
   }
   
    drush_print("Adding Person: " .  $name['firstname'] . ' ' .  $name['lastname'] . ' ' .  $profile['group']);
    $description = _gkimport_remove_line_breaks($profile['description']);    
    
    $node = new stdClass();
    $node -> type = 'person';
    $node -> status = 1;
    $node -> teaser_include = 1;
    $node -> name = $account -> name;
    $node -> uid = $account -> uid;
    $node-> og_groups = array($sid => $sid);
    // $node-> og_groups_both  = array($sid => $account -> name); // is this the right value??
    $node -> field_person_firstname[0] = array('value' => trim($name['firstname']));
    $node -> field_person_lastname[0] = array('value' => trim($name['lastname']));
    if(strlen($profile['website'])){
    $node -> field_person_website[0] = array('url' => $profile['website']);
    }
    
    //get institution
  if($profile['group'] == 'Current Research Associates'){
    $node -> body = $description;
    $node -> teaser = $description;    
 }
  else{
    $node -> field_person_institution[0] = array('value' => $description);
  }
    node_save($node);
    db_query("INSERT INTO {term_node} (nid, vid, tid) VALUES (%d, %d, %d)", $node -> nid, $node -> nid, $tid);  
  }
  //special exception
  $special_nid = db_result(db_query("SELECT nid FROM {content_type_person} WHERE field_person_firstname_value = '%s' 
  AND field_person_lastname_value = '%s'", 'Christopher' , 'Adolph'));
  $special_tid =  install_taxonomy_get_tid( 'Collaborators', $vid);
   db_query('DELETE FROM {term_node} WHERE nid = %d AND tid = %d', $special_nid, $special_tid);
   db_query("INSERT INTO {term_node} (nid, vid, tid) VALUES (%d, %d, %d)", $special_nid, $special_nid, $special_tid); 
   drush_print("Added Christopher Adolph to Collaborators group");  
}

function _gkimport_remove_line_breaks($text){
  $clean_text = '';

  $arr = explode( "\n", $text );
  if (count($arr)){
    foreach ($arr as $t){
      $clean_text .= trim($t) . ' ';
    }
  }
  return trim($clean_text);
}

/**
 * Helper function to split name into firstname/ lastname
 */
function _gkimport_split_name($name){
  $fullname = explode(' ', $name);
  $firstname = $fullname[0];
  array_shift($fullname); //remove the first name from this array (assumes there is not multiple first names)
  $lastname = implode(' ', $fullname);

  return array('firstname' => $firstname, 'lastname' => implode(' ', $fullname));
}
	
/**
 * Helper function to create Research Group vocabulary
 * @param  object $vsite
 * @return 
 *  integer -vocabulary id
 */
function _gkimport_create_rg_vocab($vsite){
    install_include(array('taxonomy'));

    //create vocabulary(s)
  $vocab_name =  'Research Group';
  $properties = array(
  'tags' => 1,
  'description' => 'Gary King Research Group',
  'help' => 'Gary King Research Group',
  );
  $content_types = array(
  'person' => 'person',
  );

  $vid = install_taxonomy_add_vocabulary($vocab_name, $content_types, $properties);
  if ($vid){
    og_vocab_write_record($vsite -> group -> nid, $vid);
    variable_set('gkimport_rg_vocab_id', $vid); //keep track of vid because other vocabs may have same name
    return $vid;
  }
}

function _gkimport_create_rg_terms($vid){
  install_include(array('taxonomy'));
  $terms = array('Current Research Associates', 'Alumni: Students', 'Alumni: Post-Docs', 'Collaborators');
  foreach($terms as $term){
  install_taxonomy_add_term($vid, $term); 
  }
}

/**
 * Implementation of hook_nodeapi()
 */
function gkimport_nodeapi(&$node, $op){ 
  if ($node -> type != 'biblio') return;
  $name = 'gking';
  $account = user_load(array('name' => $name));
  switch ($op) { 
    case 'presave':  dpm($node);
      //add the taxonomy term to the node
      if (!vsite_get_vsite()){ 
        // install_include(array('taxonomy'));
        // $site_vid = install_taxonomy_get_vid($name . '_vocabulary');
        // $node -> taxonomy['tags'][  $site_vid ] = '';
        $vid = variable_get('gkimport_ri_vocab_id', '');
        $term = trim(gkimport_match_terms($node -> title));
        if (strlen($term))  $node -> taxonomy['tags'][$vid] = $term;  //add the term here
      }
      break;
    case 'insert':
      if (!vsite_get_vsite()){
        $spaces = vsite_get_vsite_by_owner($account -> uid);
        if (count($spaces) == 1){          
        $check = db_result(db_query("SELECT nid FROM {og_ancestry} WHERE nid = %d", $node -> nid));         
          //added publication to the og
          if($check){
              db_query("UPDATE {og_ancestry} SET group_nid = %d WHERE nid = %d", $spaces[0] -> group -> nid, $node ->nid);                     
          }
          else{
          db_query("INSERT INTO {og_ancestry} (nid, group_nid) VALUES (%d, %d)", $node ->nid, $spaces[0] -> group -> nid);
          }
         drush_print(t("Imported publication: !title", array('!title'=> $node->title)));
          //save custom path
          $matches = gkimport_parse_abstract_url($node);
          if (count($matches) && strlen($matches[2])){
            //$node -> path = strstr($matches[2], 'files');
            $src = db_result(db_query("SELECT src FROM {url_alias} WHERE src = '%s'", "node/{$node -> nid}"));
            $sql = ($src) ? db_query("INSERT INTO {url_alias} (src, dst) VALUES ('%s', '%s')", "node/{$node -> nid}", strstr($matches[2], 'files'))
            : db_query("UPDATE {url_alias} SET dst = '%s' WHERE src = '%s'", strstr($matches[2], 'files'), $src);
          }
        }
        else{
          return dpm("Error occured: users has more than 1 web site"); // this is very unlikely
        }
      }
      break;
  }
}

/**
 * THESE FUNCTIONS ARE FOR DEVELOPMENT ONLY - DELETE WHEN FINISHED
 */

function gkimport_clean(){
  $path = GKIMPORT_FS_PATH . '/sites/scholar/files/gking/files';
  if(GKIMPORT_DOWNLOAD && is_dir($path)){
    $filespath = '/nfs/www/edu-harvard-iq-scholar-dev3/sites/scholar/files/gking/files/*.*';
    $cmd = "rm $filespath" . '/*.*';
    shell_exec($cmd);
    drush_print("Ran shell command: $cmd");
  }
}

